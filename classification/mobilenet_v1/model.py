# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RbTGhDu3iI9Cpdnw1NBBqXwu9LjKVcb5
"""

# TensorFlow and tf.keras
import tensorflow as tf

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)

fashion_mnist = tf.keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images.shape

len(train_labels)

train_labels

test_images.shape

len(test_labels)

plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()

train_images = train_images / 255.0

test_images = test_images / 255.0

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()

sample_shape = train_images[0].shape
img_width, img_height = sample_shape[0],sample_shape[1]
input_shape = (img_width, img_height, 1)

train_images = train_images.reshape(len(train_images),input_shape[0], input_shape[1],input_shape[2])
test_images = test_images.reshape(len(test_images),input_shape[0],input_shape[1],input_shape[2])

cnn = tf.keras.models.Sequential()

cnn.add(tf.keras.layers.SeparableConv2D(filters=32, kernel_size=3, activation='relu', padding = 'same', input_shape=input_shape))

cnn.summary()

cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

cnn.add(tf.keras.layers.SeparableConv2D(filters=64, kernel_size=3, activation='relu', padding='same'))

cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

cnn.summary()

cnn.add(tf.keras.layers.Flatten())

cnn.add(tf.keras.layers.Dense(units=64, activation='relu'))

cnn.add(tf.keras.layers.Dense(units=10, activation='softmax'))

cnn.summary()

cnn.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

cnn.summary()

cnn.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))

test_loss, test_acc = cnn.evaluate(test_images,  test_labels, verbose=2)